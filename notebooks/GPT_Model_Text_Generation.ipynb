{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874b90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from GPT.GPT_Model import TransformerBlock\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea5ae9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../GPT_Model_Configuration/GPT_config_124M.json\", \"r\") as f:\n",
    "    GPT_CONFIG_124M = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b295bcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768) \n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "436b5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec8be236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "TransformerBlock                         --\n",
       "├─MultiHeadAttention: 1-1                --\n",
       "│    └─Linear: 2-1                       590,592\n",
       "│    └─Linear: 2-2                       590,592\n",
       "│    └─Linear: 2-3                       590,592\n",
       "│    └─Linear: 2-4                       590,592\n",
       "│    └─Dropout: 2-5                      --\n",
       "├─FeedForward: 1-2                       --\n",
       "│    └─Sequential: 2-6                   --\n",
       "│    │    └─Linear: 3-1                  2,362,368\n",
       "│    │    └─GELU: 3-2                    --\n",
       "│    │    └─Linear: 3-3                  2,360,064\n",
       "├─LayerNorm: 1-3                         1,536\n",
       "├─LayerNorm: 1-4                         1,536\n",
       "├─Dropout: 1-5                           --\n",
       "=================================================================\n",
       "Total params: 7,087,872\n",
       "Trainable params: 7,087,872\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f35294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken \n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dd75d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4723ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09bc539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPT.GPT_Model import GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "541b3468",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88fec1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d97c7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "source": [
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23cb435d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "GPTModel                                 --\n",
      "├─Embedding: 1-1                         38,597,376\n",
      "├─Embedding: 1-2                         786,432\n",
      "├─Dropout: 1-3                           --\n",
      "├─Sequential: 1-4                        --\n",
      "│    └─TransformerBlock: 2-1             --\n",
      "│    │    └─MultiHeadAttention: 3-1      2,362,368\n",
      "│    │    └─FeedForward: 3-2             4,722,432\n",
      "│    │    └─LayerNorm: 3-3               1,536\n",
      "│    │    └─LayerNorm: 3-4               1,536\n",
      "│    │    └─Dropout: 3-5                 --\n",
      "│    └─TransformerBlock: 2-2             --\n",
      "│    │    └─MultiHeadAttention: 3-6      2,362,368\n",
      "│    │    └─FeedForward: 3-7             4,722,432\n",
      "│    │    └─LayerNorm: 3-8               1,536\n",
      "│    │    └─LayerNorm: 3-9               1,536\n",
      "│    │    └─Dropout: 3-10                --\n",
      "│    └─TransformerBlock: 2-3             --\n",
      "│    │    └─MultiHeadAttention: 3-11     2,362,368\n",
      "│    │    └─FeedForward: 3-12            4,722,432\n",
      "│    │    └─LayerNorm: 3-13              1,536\n",
      "│    │    └─LayerNorm: 3-14              1,536\n",
      "│    │    └─Dropout: 3-15                --\n",
      "│    └─TransformerBlock: 2-4             --\n",
      "│    │    └─MultiHeadAttention: 3-16     2,362,368\n",
      "│    │    └─FeedForward: 3-17            4,722,432\n",
      "│    │    └─LayerNorm: 3-18              1,536\n",
      "│    │    └─LayerNorm: 3-19              1,536\n",
      "│    │    └─Dropout: 3-20                --\n",
      "│    └─TransformerBlock: 2-5             --\n",
      "│    │    └─MultiHeadAttention: 3-21     2,362,368\n",
      "│    │    └─FeedForward: 3-22            4,722,432\n",
      "│    │    └─LayerNorm: 3-23              1,536\n",
      "│    │    └─LayerNorm: 3-24              1,536\n",
      "│    │    └─Dropout: 3-25                --\n",
      "│    └─TransformerBlock: 2-6             --\n",
      "│    │    └─MultiHeadAttention: 3-26     2,362,368\n",
      "│    │    └─FeedForward: 3-27            4,722,432\n",
      "│    │    └─LayerNorm: 3-28              1,536\n",
      "│    │    └─LayerNorm: 3-29              1,536\n",
      "│    │    └─Dropout: 3-30                --\n",
      "│    └─TransformerBlock: 2-7             --\n",
      "│    │    └─MultiHeadAttention: 3-31     2,362,368\n",
      "│    │    └─FeedForward: 3-32            4,722,432\n",
      "│    │    └─LayerNorm: 3-33              1,536\n",
      "│    │    └─LayerNorm: 3-34              1,536\n",
      "│    │    └─Dropout: 3-35                --\n",
      "│    └─TransformerBlock: 2-8             --\n",
      "│    │    └─MultiHeadAttention: 3-36     2,362,368\n",
      "│    │    └─FeedForward: 3-37            4,722,432\n",
      "│    │    └─LayerNorm: 3-38              1,536\n",
      "│    │    └─LayerNorm: 3-39              1,536\n",
      "│    │    └─Dropout: 3-40                --\n",
      "│    └─TransformerBlock: 2-9             --\n",
      "│    │    └─MultiHeadAttention: 3-41     2,362,368\n",
      "│    │    └─FeedForward: 3-42            4,722,432\n",
      "│    │    └─LayerNorm: 3-43              1,536\n",
      "│    │    └─LayerNorm: 3-44              1,536\n",
      "│    │    └─Dropout: 3-45                --\n",
      "│    └─TransformerBlock: 2-10            --\n",
      "│    │    └─MultiHeadAttention: 3-46     2,362,368\n",
      "│    │    └─FeedForward: 3-47            4,722,432\n",
      "│    │    └─LayerNorm: 3-48              1,536\n",
      "│    │    └─LayerNorm: 3-49              1,536\n",
      "│    │    └─Dropout: 3-50                --\n",
      "│    └─TransformerBlock: 2-11            --\n",
      "│    │    └─MultiHeadAttention: 3-51     2,362,368\n",
      "│    │    └─FeedForward: 3-52            4,722,432\n",
      "│    │    └─LayerNorm: 3-53              1,536\n",
      "│    │    └─LayerNorm: 3-54              1,536\n",
      "│    │    └─Dropout: 3-55                --\n",
      "│    └─TransformerBlock: 2-12            --\n",
      "│    │    └─MultiHeadAttention: 3-56     2,362,368\n",
      "│    │    └─FeedForward: 3-57            4,722,432\n",
      "│    │    └─LayerNorm: 3-58              1,536\n",
      "│    │    └─LayerNorm: 3-59              1,536\n",
      "│    │    └─Dropout: 3-60                --\n",
      "├─LayerNorm: 1-5                         1,536\n",
      "├─Linear: 1-6                            38,597,376\n",
      "=================================================================\n",
      "Total params: 163,037,184\n",
      "Trainable params: 163,037,184\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aef3221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPT.Text_Generation import generate_simple_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a85c93e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded text: [15496, 11, 1312, 716]\n",
      "Encoded tensor shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, i am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(f\"Encoded text: {encoded}\")\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(f\"Encoded tensor shape: {encoded_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64a83125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,  1312,   716, 42280, 22255,  8170, 35468, 48478, 12309]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = generate_simple_text(model=model, \n",
    "                           idx = encoded_tensor, max_new_tokens=6, \n",
    "                           context_size=GPT_CONFIG_124M[\"context_length\"])\n",
    "print(f\"Output: {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7a9614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Length: 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Output Length: {len(out[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a39492d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, i am lil Nak Exper amenitiesBomb peaceful\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee73efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
