{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d0913e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43917dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from GPT.Tokenization import text_to_tokens, token_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09a80fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc755bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb454c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPT.GPT_Model import GPTModel, GPT_CONFIG_124M\n",
    "model = GPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70e54aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abcf8ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(logits, dim = -1) # Probability of each token in vocabulory \n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d512852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[10723],\n",
      "         [48768],\n",
      "         [11766]],\n",
      "\n",
      "        [[41373],\n",
      "         [47269],\n",
      "         [18757]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim = -1, keepdim=True)\n",
    "print(f\"Token IDs:\\n {token_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40a6ec02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Batch 1:  effort moves you\n",
      "Output Batch 1: Watch043pert\n"
     ]
    }
   ],
   "source": [
    "print(f\"Target Batch 1: {token_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Output Batch 1: {token_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf937488",
   "metadata": {},
   "source": [
    "## **Cross-Entropy Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eb24734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([2.8425e-05, 9.7405e-06, 8.4400e-06])\n",
      "Text 2: tensor([5.3366e-06, 1.9943e-05, 1.7796e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(f\"Text 1: {target_probas_1}\")\n",
    "\n",
    "text_idx = 1 \n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(f\"Text 2: {target_probas_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7683ac37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.4683, -11.5392, -11.6825, -12.1409, -10.8226, -10.9366])\n"
     ]
    }
   ],
   "source": [
    "# Logarithm to all the token probabilities \n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3b16c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-11.2650)\n"
     ]
    }
   ],
   "source": [
    "# Avg probability for each token \n",
    "avg_log_prob = torch.mean(log_probas)\n",
    "print(avg_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3e1bf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.2650)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probs = avg_log_prob * -1\n",
    "print(neg_avg_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c765c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logits shape: {logits.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22b234f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits flat: torch.Size([6, 50257])\n",
      "Target flat: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(f\"Logits flat: {logits_flat.shape}\")\n",
    "print(f\"Target flat: {targets_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ca3412d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.2650)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27effba9",
   "metadata": {},
   "source": [
    "## **Perplexity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9637ff5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(78043.2500)\n"
     ]
    }
   ],
   "source": [
    "# Concept related to cross entropy loss, Perplexity is simply the exponential of the cross-entropy loss \n",
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a660f",
   "metadata": {},
   "source": [
    "## **Evaluating LLM Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57785019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open(\"C:\\\\Users\\\\hites\\\\OneDrive\\\\Desktop\\\\GPT\\\\data\\\\the-verdict.txt\", 'r', encoding='utf-8')  as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5567f6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b650c256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(raw_text)\n",
    "total_tokens = len(tokenizer.encode(raw_text))\n",
    "\n",
    "print(f\"Characters: {total_characters}\")\n",
    "print(f\"Tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be77dff0",
   "metadata": {},
   "source": [
    "### **Dataset & DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "239ac53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader \n",
    "from GPT.Dataset_and_DataLoaders import GPTDataset, create_dataloader_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94082a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Validation ratio \n",
    "train_ratio = 0.90 \n",
    "split_idx = int(train_ratio * len(raw_text))\n",
    "train_data = raw_text[:split_idx]\n",
    "val_data = raw_text[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a9b28f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18431, 2048)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31f8a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 256, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eca8c892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M[\"context_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81d8aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data, \n",
    "    batch_size=2, \n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"], \n",
    "    stride=GPT_CONFIG_124M[\"context_length\"], \n",
    "    drop_last=True, \n",
    "    shuffle=True, \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data, \n",
    "    batch_size=2, \n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"], \n",
    "    stride=GPT_CONFIG_124M[\"context_length\"], \n",
    "    drop_last=False,  \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f069519e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1e2c4da2ec0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1e2c4da2770>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "059fa0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0dc06933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "Length of train_loader:  9\n",
      "\n",
      "Validation Loader\n",
      "\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "Length of val_loader:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Loader\")\n",
    "for X, y in train_loader:\n",
    "    print(X.shape, y.shape)\n",
    "print(\"Length of train_loader: \", len(train_loader))\n",
    "\n",
    "print(\"\\nValidation Loader\\n\")\n",
    "for X, y in val_loader:\n",
    "    print(X.shape, y.shape)\n",
    "print(\"Length of val_loader: \", len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81decf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Tokens : 4608\n",
      "Val Tokens : 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0 \n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0 \n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(f\"Training Tokens : {train_tokens}\")\n",
    "print(f\"Val Tokens : {val_tokens}\")\n",
    "print(f\"All tokens: {train_tokens + val_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27791b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPT.GPT_Model import GPTModel\n",
    "model = GPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f240051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ce819",
   "metadata": {},
   "source": [
    "### **Calculating Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "115a806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPT.Loss_Calculation import calc_loss_batch, calc_loss_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "665cedfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 11.001539760165745\n",
      "Val Loss: 10.995049476623535\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f\"Training Loss: {train_loss}\")\n",
    "print(f\"Val Loss: {val_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
